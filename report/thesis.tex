% do not change these two lines (this is a hard requirement
% there is one exception: you might replace oneside by twoside in case you deliver 
% the printed version in the accordant format
\documentclass[11pt,titlepage,oneside,openany]{book}
\usepackage{times}


\usepackage{graphicx}
\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{wasysym}

\usepackage[hyphens]{url}

\usepackage{ntheorem}

% \usepackage{paralist}
\usepackage{tabularx}


\usepackage[table,xcdraw]{xcolor}
\usepackage{pdflscape}
\usepackage{afterpage}
\usepackage{rotating}
\usepackage{makecell}

% this packaes are useful for nice algorithms
\usepackage{algorithm}
\usepackage{algorithmic}

% well, when your work is concerned with definitions, proposition and so on, we suggest this
% feel free to add Corrolary, Theorem or whatever you need
\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}

%table spacing
\newcolumntype{b}{X}
\newcolumntype{s}{>{\hsize=.3\hsize}X}
\newcolumntype{m}{>{\hsize=.5\hsize}X}

% its always useful to have some shortcuts (some are specific for algorithms
% if you do not like your formating you can change it here (instead of scanning through the whole text)
\renewcommand{\algorithmiccomment}[1]{\ensuremath{\rhd} \textit{#1}}
\def\MYCALL#1#2{{\small\textsc{#1}}(\textup{#2})}
\def\MYSET#1{\scshape{#1}}
\def\MYAND{\textbf{ and }}
\def\MYOR{\textbf{ or }}
\def\MYNOT{\textbf{ not }}
\def\MYTHROW{\textbf{ throw }}
\def\MYBREAK{\textbf{break }}
\def\MYEXCEPT#1{\scshape{#1}}
\def\MYTO{\textbf{ to }}
\def\MYNIL{\textsc{Nil}}
\def\MYUNKNOWN{ unknown }
% simple stuff (not all of this is used in this examples thesis
\def\INT{{\mathcal I}} % interpretation
\def\ONT{{\mathcal O}} % ontology
\def\SEM{{\mathcal S}} % alignment semantic
\def\ALI{{\mathcal A}} % alignment
\def\USE{{\mathcal U}} % set of unsatisfiable entities
\def\CON{{\mathcal C}} % conflict set
\def\DIA{\Delta} % diagnosis
% mups and mips
\def\MUP{{\mathcal M}} % ontology
\def\MIP{{\mathcal M}} % ontology
% distributed and local entities
\newcommand{\cc}[2]{\mathit{#1}\hspace{-1pt} \# \hspace{-1pt} \mathit{#2}}
\newcommand{\cx}[1]{\mathit{#1}}
% complex stuff
\def\MER#1#2#3#4{#1 \cup_{#3}^{#2} #4} % merged ontology
\def\MUPALL#1#2#3#4#5{\textit{MUPS}_{#1}\left(#2, #3, #4, #5\right)} % the set of all mups for some concept
\def\MIPALL#1#2{\textit{MIPS}_{#1}\left(#2\right)} % the set of all mips





\begin{document}

\pagenumbering{roman}
% lets go for the title page, something like this should be okay
\begin{titlepage}
	\vspace*{2cm}
  \begin{center}
   {\Large The Extremes of Good and Evil\\}
   \vspace{2cm} 
   {Master Thesis\\}
   \vspace{2cm}
   {presented by\\
    Earl Hickey \\
    Matriculation Number 9083894\\
   }
   \vspace{1cm} 
   {submitted to the\\
    Data and Web Science Group\\
    Prof.\ Dr.\ Right Name Here\\
    University of Mannheim\\} \vspace{2cm}
   {August 2014}
  \end{center}
\end{titlepage} 

% no lets make some add some table of contents
\tableofcontents
\newpage

\listoffigures

\listoftables

% evntuelly you might add something like this
% \listtheorems{definition}
% \listtheorems{proposition}

\newpage


% okay, start new numbering ... here is where it really starts
\pagenumbering{arabic}

\chapter{Phase I - Data Translation}
\label{cha:data-translation}
 
\section{Use Case \& Data Profiling}
The goal of the project is to aggregate company information from several sources. To this end we used the suggestions from the project into slides as a foundation for our use case. We also included an additional source and amended the dbpedia query to extract further relevant information. Thus, the relevent entity will be a company.
We relied on 4 different datasources which are profiled in Table \ref{tab:dataset-overview}

\begin{table}[]
	%TODO dbpedia query
	\label{tab:dataset-overview}
	\small
	\centering
	\begin{tabularx}{\textwidth}{mmsssb}
		Dataset   & Source(*)                                                       & Format                & \#E\textsuperscript{1}       & \#A \textsuperscript{2} & List Of Attributes                                                                                                                                                          \\\hline
		kaggle    & \url{kaggle.com/kaleab1/companies}                        & csv                  & 7.1M                 & 11               & ID, name, domain, year founded (MV 50\%), industry, size range, locality   (MV 35\%), country (MV 33\%), linkedin url, current employee estimate, total   employee estimate \\
		forbes    & \url{kaggle.com/ash316/forbes-top-2000-companies}         & csv                 & 2.000                & 9                & Company, Country, Sales, Profits, Assets,   Market Value, Sector, Industry                                                                                                  \\
		dataworld (dw)&
		\url{data.world/youngx62/worlds-largest-companies-by-revenue} & csv                  & 1.924                & 10               & Global Rank, Company, Sales, Profits, Assets, Market Value, Country,   Continent, Latitude, Longitude                                                                       \\
		dbpedia   & Query provided in Appendix                                      & json   &  3.986                &                  & Name, industry\_label, domain,   founding\_year, ceos, no\_emp (MV 33\%), country (MV 93\%), location (MV 76\%),   revenue (MV 47\%), income (MV 66\%), assets (MV 70\%)    \\
	\end{tabularx}
\caption[Dataset Overview]%
{Dataset Overview. \small\medspace\medspace All dataset only refer to the class "Company", \textsuperscript{1}\# of Entities, \textsuperscript{2}\# of Attributes}

\end{table}


\begin{table}[]
	\begin{tabular}{llll}
		Class Name   & Attribute   Name            & Attribute Type & Contained in DS... \\\hline
		Company      & name                        & String         & Kaggle, Forbes,   dbpedia, dw              \\
		Company      & domain                      & String         & Kaggle, dbpedia                            \\
		Company & Year founded                & Integer        & Kaggle, dbpedia                            \\
		Company      & Industry                    & String/List    & Kaggle, Forbes, dbpedia                    \\
		Company      & Size\_range                 & Category       & Kaggle (can also be   derived for dbpedia) \\
		Company      & locality                    & String         & Kaggle, dbpedia                            \\
		Company      & Country                     & String         & Kaggle, Forbes, dw,   dbpedia              \\
		Company      & Linkedin url                & String         & Kaggle                                     \\
		Company      & Current   employee estimate & Integer        & Kaggle, dbpedia                            \\
		Company      & Total employee   estimate   & String         & Kaggle                                     \\
		Company      & Sales                       & Integer        & Forbes, dw, dbpedia                        \\
		Company      & Profits                     & Integer        & Forbes, dw, dbpedia                        \\
		Company      & Assets                      & Integer        & Forbes, dw, dbpedia                        \\
		Company      & Market Value                & Integer        & Forbes, dw, dbpedia                        \\
		Company      & sector                      & String         & Forbes                                     \\
		Company      & Global Rank                 & Integer        & Dw                                         \\
		Company      & Latitude                    & Decimal        & dw                                         \\
		Company      & Longitude                   & Decimal        & Dw                                         \\
		Company      & ceos                        & list           & Dbpedia                                   
	\end{tabular}
\end{table}



\section{Consolidated Schema \& Transformations}


\chapter{Phase II - Identity Resolution}
\label{cha:identity-resolution}

\section{Gold Standard}
\label{sec:gold-standard-IR}

In order to create the gold standard we ran initial identity resolutions with cheap matching rules. With a threshold of 0.3 we used three different matching rules: \begin{itemize}
	\item Jaccard-3-Grams on company names (with frequent tokens removed)
	\item Levensthein Similarity on company names (with frequent tokens removed)
	\item a combined matching rule of the above (50/50) 
	%TODO !! --> maybe use something different, add rule IDs?
\end{itemize}
%TODO add file references?? File Gold Standard integration.
%TODO global matching
%TODO source for string matching https://ebookcentral.proquest.com/lib/unimannheim-ebooks/reader.action?docID=945451
The results were then combined into one file which for each individual correspondence outlined the similarity calculated by every similarity measure as well as the company names.

We then labeled the matches into matching record pairs, corner-case matches and non-matches, and non-matches. 
Correspondences were labeld as certain matches if at least one of the similarity scores had a high matching threshold $>$ 0.95 and an actual match was present.
Correspondences were labeled as fuzzy if the similarity measures did not agree on a rating which was indicated by the average similarity, i.e. one similarity measure had a high certainty while the other one had a low certainty.
Correspondecnes with low average similarity were labeled as non-matches after verifying that they indeed did not match.
To achieve the distribution according to the rule of thumb outlined in the lecture, which states to include 20\% matching record matching pairs, 30\% corner-case matches and non-matches (fuzzy), and 50\% non-matching record pairs a random sample out of the labled correspondences was drawn.
%TODO was their a problem to achieve this distribution?
The data was then split into train and test set using a python script, with a test size of 0.25 and stratified on the gold standard category.

%TODO Note on balance of gold standard, positives and negatives

After running several identity resolutions the evaluation logs were analyzed and the gold standard was amended to cater to the identified false positive correspondences (according to the previous gold standard) by adding them to the gold standard, usually as corner-cases. 

\section{Matching Rules}
\label{sec:matching-rules}

\subsection{General Setup}
The company name was the sole variable we could rely on during the identity resolution. To this end, we implemented several string-based comparators which are outlined in table \ref{table:comparators} and subsequently combined them to form different matching rules. We implemented a plethora of different matching rules, therefore we limit ourselves to the top 10 based on their F1-scores.
%TODO why these comparators - maybe put with challenges?
Every comparator had options to include certain pre- and post-processing steps. Preprocessing steps generally included lowercasing, removal of punctuation, and removal of whitespaces (the latter was omitted for token based similarity metrics). We also implemented post-processing capabilities. These included a threshold after which the similarity was set to zero, and an option to boost or penalize the similarity based on a certain threshold. For example, a similarity might be boosted up using a particular function above a threshold of 0.8 and penalized below. %TODO might be necessary to outline this a little bit more, which type of functions and why those



\begin{table}[b]
	\label{table:comparators}
	
	\begin{tabular}{lllccc}
		& \multicolumn{2}{l}{}                              & \multicolumn{2}{l}{Preprocessing}                   & \\
		ID & Similarity   measure       & Parameters           & \multicolumn{1}{l}{PWL\textsuperscript{1}} & \multicolumn{1}{l}{Rm FT\textsuperscript{2}} & Focus\\
		1  & Jaccard on ngrams          & n: ngram   length    & \checked & (\checked)                     & Overlap\\
		2  & Jaccard on tokens          &                      & *                       & (\checked)                       &Overlap\\
		3  & Levensthein                &                      & \checked & (\checked)                       &Typos / Edit-distance\\
		4  & Longest Common Subsequence & Normalization   Flag & \checked & (\checked)                       & Order\\
		5  & RogueN on Tokens \cite{lin_rouge_2004} & & \checked & -  & Overlap                      
	\end{tabular}

\caption[Comparator Overview]%
{Comparator Overview \small\medspace\medspace \textsuperscript{1}Lowercasing and removal of punctuation and whitespaces -  latter not removed for token-based similarity metrics, \textsuperscript{2}Removal of frequent tokens, * Preprocessing done by pre-implemented similarity measure, \checked \space used in comparator, (\checked) optional}

\end{table}

\subsection{Major Challenge - Named Entity Matching}

As a first challenge in our project we had to find out that company names are inherently difficult to match. We found ourselves facing similar challenges as the Dutch Central Bank \footnote{https://medium.com/dnb-data-science-hub/company-name-matching-6a6330710334}. %TODO make proper bibliographic reference
As with named entities in general every data source has a different level of detail, different data quality, and use of abbreviations among others. Regarding this, our matching rules had to cater to the following challenges:
\begin{enumerate}
	\item \textbf{Company Name:} In part the name of the legal entity was used, in other cases the name of the group, and in other cases some abbreviation (e.g., Anheuser-Busch InBev Germany Holding GmbH vs. Anheuser-Busch InBev vs. AB InBev) or tokens of the name were omitted (e.g., Royal Dutch Shell vs. Shell). While all these names refer to the same entity, our matching rules evolved to address this.
	\item \textbf{Data Quality:} We had to cope with general data quality issues which are represented for example by typos.
	\item \textbf{Frequent tokens:} There are several tokens that have a higher frequency in company names. These include for example legal entity descriptors (limited, incorporated, ...), industy descriptors (bank, motors, pharmaceuticals, ...) and stop words (the, and, of ...). These may let names seem more similar than they actually are (General Motors vs. Hyundai Motors). We analyzed frequent tokens across our datasets and provided the matching rules with the option to remove frequent tokens.
	\item \textbf{Token order:} Company names of different companies might be composed of similar tokens in a different order. Token-based similarity metrics alone would classify such names as similar altough they are not (Commercial National Financial vs. National Financial Group). This means that token order matters.
\end{enumerate}

We adressed these challenges by combining comparators with different strengths in matching rules which we systematically evaluated at different final mathching thresholds. We also implemented some new similarity metrics to cater to our needs (Comparator 4 and 5).
We also faced a second challenge concerning dataset sizes which will be outlined in \ref{sec:blockers}.

\subsection{Evaluation}

We evaluated local and global matching strategies. In table XXX the best matching rule for each threshold is presented.





\section{Blockers}
\label{sec:blockers}

We used three different types of blockers (no blocker, symmetric, sorted neighborhood) and different blocking key generators. The following key generators were implemented, all with certain preprocessing options: \begin{enumerate}
	\item First letter of the company name.
	\item Qgrams and first letter of the company name. \cite{gravano_approximate_nodate} suggest this blocking technique to ensure a low degree of missed pairs while staying computationally efficient. %TODO run without first letter
	\item N starting characters of each company name token.
\end{enumerate}

Especially the last blocker was born out of our second challenge, the large dataset size of the kaggle dataset.


\section{Analysis of Errors}
\label{sec:errors}


\chapter{Phase III - Data Fusion}
\label{cha:data-fusion}


%TODO Style Table
\begin{table}[h]

\begin{center}
\begin{tabular*}{\textwidth}{@{\extracolsep{\fill}}>{\scriptsize}l|>{\scriptsize}c>{\scriptsize}c>{\scriptsize}c|>{\scriptsize}c>{\scriptsize}c>{\scriptsize}c>{\scriptsize}c} 
& \multicolumn{3}{>{\scriptsize}c|}{Baselines} & \multicolumn{4}{>{\scriptsize}c}{Decision Tree} \\\hline
Ontology & M(edian) & G(ood) & E(vil) & results & $\Delta$-M & $\Delta$-G & $\Delta$-E \\\hline\hline
\#301 & 0.825 & 0.877 & 0.877 & 0.855 & +0.030 & -0.022 & -0.022 \\\hline
\#302 & 0.709 & 0.753 & 0.753 & 0.753 & +0.044 & +0.000 & +0.000 \\\hline
\#303 & 0.804 & 0.860 & 0.891 & 0.816 & +0.012 & -0.044 & -0.075 \\\hline
\#304 & 0.940 & 0.961 & 0.961 & 0.967 & +0.027 & +0.006 & +0.006 \\\hline
\bfseries Average & \bfseries 0.820 & \bfseries 0.863 & \bfseries 0.871 & \bfseries 0.848 & \bfseries +0.028 & \bfseries -0.015 & \bfseries -0.023 

\end{tabular*}
\caption[Good vs. Evil]{Comparison between the Good and the Evil}
\label{tab:confonly}
\end{center}
\end{table}



If you cite something, do it in the following way. 
\begin{itemize}
	\item Conference Proceedings: This problem is typically addressed by approaches for selecting the optimal matcher based on the nature of the matching task and the known characteristics of the different matching systems. Such an approach is described in \cite{mochol08matcher}.
	\item Journal Article: S-Match, described in \cite{giunchiglia2008semanticmatching}, employs sound and complete reasoning procedures. Nevertheless, the underlying semantic is restricted to propositional logic due to the fact that ontologies are interpreted as tree-like structures.
	\item Book: According to Euzenat and Shvaiko \cite{euzenat07matcherbook}, we define a correspondence as follows.
\end{itemize}
These are some randomly chosen examples from other works. Take a look at the end of this thesis so see how the bibliography is included.



\bibliographystyle{plain}
\bibliography{thesis-ref}


\appendix

\chapter{Program Code / Resources}
\label{cha:appendix-a}

The source code, a documentation, some usage examples, and additional test results are available at ...

They as well as a PDF version of this thesis is also contained on the CD\chapter{Phase II - Identity Resolution}
\label{cha:intro}-ROM attached to this thesis.

\chapter{Further Experimental Results}
\label{cha:appendix-b}

In the following further experimental results are ...


\newpage


\pagestyle{empty}


\section*{Ehrenw\"ortliche Erkl\"arung}
Ich versichere, dass ich die beiliegende Master-/Bachelorarbeit ohne Hilfe Dritter
und ohne Benutzung anderer als der angegebenen Quellen und Hilfsmittel
angefertigt und die den benutzten Quellen w\"ortlich oder inhaltlich
entnommenen Stellen als solche kenntlich gemacht habe. Diese Arbeit
hat in gleicher oder \"ahnlicher Form noch keiner Pr\"ufungsbeh\"orde
vorgelegen. Ich bin mir bewusst, dass eine falsche Er- kl\"arung rechtliche Folgen haben
wird.
\\
\\

\noindent
Mannheim, den 31.08.2014 \hspace{4cm} Unterschrift

\end{document}
